{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Routes_Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UM4liCXfz1j"
      },
      "source": [
        "# 1. Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB4Z12ngox3B"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "from math import sqrt\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2NymuYmvPtq",
        "outputId": "4ac3ed01-0194-4de9-bda6-1ba8ca20bb9e"
      },
      "source": [
        "!gdown --id 1-RXYMh61x9asaVU_w5tDHtq0CMmp_Rdn\n",
        "!gdown --id 1--znLUhuYqoMMqQo1Gnf6WafrzzniIFL"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-RXYMh61x9asaVU_w5tDHtq0CMmp_Rdn\n",
            "To: /content/TrainData.csv\n",
            "2.58GB [00:14, 176MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--znLUhuYqoMMqQo1Gnf6WafrzzniIFL\n",
            "To: /content/TestData.csv\n",
            "645MB [00:03, 189MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X5jRzXhf8A3"
      },
      "source": [
        "# 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4tPkg7ApZfL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "b5d250a0-a271-4dc6-c4dd-d52a23eb369d"
      },
      "source": [
        "# Read data\n",
        "\n",
        "%%time\n",
        "# https://drive.google.com/file/d/1-RXYMh61x9asaVU_w5tDHtq0CMmp_Rdn/view?usp=sharing\n",
        "file_path_train = 'TrainData.csv'\n",
        "# https://drive.google.com/file/d/1--znLUhuYqoMMqQo1Gnf6WafrzzniIFL/view?usp=sharing\n",
        "file_path_test = 'TestData.csv'\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(file_path_train)\n",
        "test_df = pd.read_csv(file_path_test)\n",
        "\n",
        "print(train_df.shape)\n",
        "display(train_df.head(1))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50253, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>userId</th>\n",
              "      <th>gender</th>\n",
              "      <th>sport</th>\n",
              "      <th>duration</th>\n",
              "      <th>calories</th>\n",
              "      <th>distance</th>\n",
              "      <th>avg_heart_rate</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>altitude</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>heart_rate</th>\n",
              "      <th>speed</th>\n",
              "      <th>url</th>\n",
              "      <th>derived_distance</th>\n",
              "      <th>derived_speed</th>\n",
              "      <th>time_elapsed</th>\n",
              "      <th>validate</th>\n",
              "      <th>avg_alti</th>\n",
              "      <th>change_alti</th>\n",
              "      <th>max_alti</th>\n",
              "      <th>min_alti</th>\n",
              "      <th>diff_alti</th>\n",
              "      <th>avg_speed</th>\n",
              "      <th>Cluster</th>\n",
              "      <th>Route</th>\n",
              "      <th>Route_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>611012078</td>\n",
              "      <td>2568526</td>\n",
              "      <td>male</td>\n",
              "      <td>run</td>\n",
              "      <td>3158</td>\n",
              "      <td>830.588</td>\n",
              "      <td>10.02</td>\n",
              "      <td>154.914</td>\n",
              "      <td>[7.099486151710153, 7.0994688011705875, 7.0993...</td>\n",
              "      <td>[43.68301374837756, 43.683006623759866, 43.682...</td>\n",
              "      <td>[137.8, 137.8, 138.2, 138.8, 138.8, 138.6, 139...</td>\n",
              "      <td>[1443653973, 1443653974, 1443653978, 144365398...</td>\n",
              "      <td>[140, 140, 141, 149, 149, 150, 153, 157, 160, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.endomondo.com/users/2568526/workou...</td>\n",
              "      <td>[0.0016049429213742246, 0.01260242289257531, 0...</td>\n",
              "      <td>[5.777794516947209, 10.005378447215753, 10.428...</td>\n",
              "      <td>[1, 4, 5, 1, 5, 6, 11, 4, 6, 7, 8, 7, 7, 9, 5,...</td>\n",
              "      <td>True</td>\n",
              "      <td>87.8552</td>\n",
              "      <td>756.8</td>\n",
              "      <td>139.4</td>\n",
              "      <td>76.0</td>\n",
              "      <td>63.4</td>\n",
              "      <td>11.574343</td>\n",
              "      <td>1</td>\n",
              "      <td>('run', 1)</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id   userId gender sport  ...  avg_speed  Cluster       Route  Route_id\n",
              "0  611012078  2568526   male   run  ...  11.574343        1  ('run', 1)         9\n",
              "\n",
              "[1 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24.6 s, sys: 5.38 s, total: 30 s\n",
            "Wall time: 30 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KrUe3ktf__i"
      },
      "source": [
        "# 3. Find workout records that return to start point at the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHVEnvc5yGbb"
      },
      "source": [
        "# Define function to compute distance based on Latitude, Longitude, Altitude\n",
        "def geodis(lat_0, lon_0, alt_0, lat_1, lon_1, alt_1):\n",
        "    dis = geodesic((lat_0, lon_0), (lat_1, lon_1)).km\n",
        "    dis = sqrt(dis**2 + (alt_0/1000-alt_1/1000)**2)\n",
        "    return dis\n",
        "\n",
        "# Define function to check if a workout record has returned to start point at the end\n",
        "\n",
        "\n",
        "def isback(df_row, num_to_check):\n",
        "\n",
        "\n",
        "    '''\n",
        "    df_row: a row of dataframe\n",
        "    num_to_check: number of points to check\n",
        "\n",
        "    1. We take num_to_check points at the beginning of workout route and num_to_check points\n",
        "    at the end of the workout route\n",
        "\n",
        "    2. We compute the distances between each point at the beginning with all points at the end respectively\n",
        "\n",
        "    3. If one distance is smaller than threshold, then we return 1 else we return 0\n",
        "\n",
        "    '''\n",
        "\n",
        "    if df_row.sport == 'run':\n",
        "        thres = 0.02\n",
        "    else:\n",
        "        thres = 0.04\n",
        "\n",
        "    lat_head = eval(df_row.latitude)[0:num_to_check]\n",
        "    lon_head = eval(df_row.longitude)[0:num_to_check]\n",
        "    alt_head = eval(df_row.altitude)[0:num_to_check]\n",
        "    lat_tail = eval(df_row.latitude)[-num_to_check:]\n",
        "    lon_tail = eval(df_row.longitude)[-num_to_check:]\n",
        "    alt_tail = eval(df_row.altitude)[-num_to_check:]\n",
        "\n",
        "    dis_list = []\n",
        "\n",
        "    for i in range(0, num_to_check):\n",
        "        dis = [geodis(lat_head[i], lon_head[i], alt_head[i], lat_tail[j],\n",
        "                      lon_tail[j], alt_tail[j]) for j in range(0, num_to_check)]\n",
        "        dis_list.extend(dis)\n",
        "\n",
        "    if min(dis_list) < thres:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDcDXrcuj7tS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d6404b-3a2a-4604-86fb-32ef16523c0c"
      },
      "source": [
        "%%time\n",
        "\n",
        "train_df['isback'] = train_df.apply(lambda x: isback(x, 5), axis=1)\n",
        "test_df['isback'] = test_df.apply(lambda x: isback(x, 5), axis=1)\n",
        "\n",
        "print(train_df.isback.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    29470\n",
            "1    20783\n",
            "Name: isback, dtype: int64\n",
            "CPU times: user 8min 23s, sys: 1.72 s, total: 8min 25s\n",
            "Wall time: 8min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOnpxZ4EgNHL"
      },
      "source": [
        "# 4. Extend workout routes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lucxJK9FgK5e"
      },
      "source": [
        "# Extract rows where workout route has returned to starting point at the end\n",
        "\n",
        "adjust_train_df = train_df[train_df.isback==1].copy()\n",
        "adjust_test_df = test_df[test_df.isback==1].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5V6-kZzwFlJ"
      },
      "source": [
        "# Define function to create new sequential features\n",
        "\n",
        "def update_sequence(df_row, max_extend_point):\n",
        "\n",
        "\n",
        "    '''\n",
        "    df_row: a row of dataframe\n",
        "    max_extend_point: maximum number of points to extend\n",
        "\n",
        "\n",
        "    1. We randomly draw a number as the number of points to extend:\n",
        "    ext_len\n",
        "\n",
        "    2. We extract the number of points from start of workout sequence:\n",
        "    lat_head, lon_head, alt_head, distance_head\n",
        "\n",
        "    3. We generate Gaussian noise and add to the latitude and longitude of the\n",
        "    extracted sequence:\n",
        "    lat_head_noise, lon_head_noise\n",
        "\n",
        "    4. We re-calculate distance sequence due to added noise to latitude and longitude\n",
        "\n",
        "    5. Because we will extend a number of points to sequence data, we also randomly\n",
        "    remove same number of points from original sequence so that the sequence length\n",
        "    is unchanged:\n",
        "    tmp_alt, tmp_distance\n",
        "\n",
        "    6. For dropped points, we re-calculate the distance and speed of neighbouring point\n",
        "\n",
        "    7. For altitude and distance, we concatenate extracted points from beginning of\n",
        "    sequence and original sequence with points randomly dropped:\n",
        "    alt_head+tmp_alt, distance_head+tmp_distance\n",
        "\n",
        "    8. For speed, heart rate, we keep original sequence with points randomly dropped:\n",
        "    tmp_heart, tmp_speed\n",
        "\n",
        "    9. We also return the index of the last point from the original sequence:\n",
        "    complete_idx\n",
        "    '''\n",
        "\n",
        "    # Randonly draw the number of points to extend\n",
        "    ext_len = random.randrange(30, max_extend_point)\n",
        "\n",
        "    # Extract number of points from start of workout sequence\n",
        "    lat_head = eval(df_row.latitude)[0:ext_len]\n",
        "    lon_head = eval(df_row.longitude)[0:ext_len]\n",
        "    alt_head = eval(df_row.altitude)[0:ext_len]\n",
        "    distance_head = eval(df_row.derived_distance)[0:ext_len]\n",
        "\n",
        "    # Generate Gaussian noise\n",
        "    max_noise_lat = np.absolute(np.array(lat_head).mean()/100000000.)\n",
        "    max_noise_lon = np.absolute(np.array(lat_head).mean()/100000000.)\n",
        "\n",
        "    noise_lat = np.random.normal(0, max_noise_lat, ext_len)\n",
        "    noise_lon = np.random.normal(0, max_noise_lon, ext_len)\n",
        "\n",
        "    # Add Gaussian noise to latitude and longitude of extended route\n",
        "    lat_head_noise = np.add(lat_head, noise_lat)\n",
        "    lon_head_noise = np.add(lon_head, noise_lon)\n",
        "\n",
        "    # Update distance array based on new latitude and longitude with noise\n",
        "    dis_tail = distance_head[-1]\n",
        "    distance_head = np.array([geodis(lat_head_noise[idx], lon_head_noise[idx], alt_head[idx],\n",
        "                                    lat_head_noise[idx+1], lon_head_noise[idx+1], alt_head[idx+1]) for idx in range(len(distance_head)-1)])\n",
        "    distance_head = np.append(distance_head, dis_tail)\n",
        "\n",
        "\n",
        "    # Sample indices to drop from original route\n",
        "    # we don't want to touch the head and tail point\n",
        "    drop_indices = random.sample(range(1, 498), ext_len)\n",
        "\n",
        "    # Adjust distance and speed due to dropped points\n",
        "\n",
        "    # Get value from each cell for each feature\n",
        "    tmp_lat = eval(df_row.latitude)\n",
        "    tmp_lon = eval(df_row.longitude)\n",
        "    tmp_alt = eval(df_row.altitude)\n",
        "    tmp_heart = eval(df_row.heart_rate)\n",
        "    tmp_speed = eval(df_row.derived_speed)\n",
        "    tmp_distance = eval(df_row.derived_distance)\n",
        "    tmp_timestamp = eval(df_row.timestamp)\n",
        "\n",
        "    tmp_df = pd.DataFrame(data=[tmp_lat[:499],\n",
        "                                tmp_lon[:499],\n",
        "                                tmp_alt[:499],\n",
        "                                tmp_heart[:499],\n",
        "                                tmp_speed[:499],\n",
        "                                tmp_distance[:499],\n",
        "                                tmp_timestamp[:499]]).T\n",
        "\n",
        "    tmp_df.rename(columns={0: 'latitude',\n",
        "                            1: 'longitude',\n",
        "                            2: 'altitude',\n",
        "                            3: 'heart_rate',\n",
        "                            4: 'derived_speed',\n",
        "                            5: 'derived_distance',\n",
        "                            6: 'timestamp'}, inplace=True)\n",
        "\n",
        "    # Adjust distance and speed due to dropped points\n",
        "    for idx in drop_indices:\n",
        "\n",
        "        # Find idx of previous row in case the row is already deleted\n",
        "        prev_idx = idx-1\n",
        "        while prev_idx not in tmp_df.index:\n",
        "            prev_idx -= 1\n",
        "\n",
        "        # Find idx of next row in case the row is already deleted\n",
        "        next_idx = idx+1\n",
        "        while next_idx not in tmp_df.index:\n",
        "            next_idx += 1\n",
        "\n",
        "        # idx point will be deleted, we add idx point distance to the distance at previous point\n",
        "        tmp_df.loc[prev_idx, 'derived_distance'] += tmp_df.loc[idx,\n",
        "                                                                'derived_distance']\n",
        "        # Re-calculate speed based on new distance for previous point\n",
        "        tmp_df.loc[prev_idx, 'derived_speed'] = tmp_df.loc[prev_idx, 'derived_distance'] / \\\n",
        "            ((tmp_df.loc[next_idx, 'timestamp'] -\n",
        "                tmp_df.loc[prev_idx, 'timestamp'])/3600)\n",
        "        # Drop row at idx point\n",
        "        tmp_df.drop([idx], inplace=True)\n",
        "\n",
        "    # Get reduced feature arrays\n",
        "    tmp_lat = tmp_df.latitude.to_numpy()\n",
        "    tmp_lon = tmp_df.longitude.to_numpy()\n",
        "    tmp_alt = tmp_df.altitude.to_numpy()\n",
        "    tmp_heart = tmp_df.heart_rate.to_numpy()\n",
        "    tmp_speed = tmp_df.derived_speed.to_numpy()\n",
        "    tmp_distance = tmp_df.derived_distance.to_numpy()\n",
        "\n",
        "    # Store idx where original workout completes\n",
        "    complete_idx = tmp_lat.shape[0]-1\n",
        "\n",
        "    # Update distance between last point of original workout route to first point of extended route\n",
        "    tmp_distance[-1] = geodis(tmp_lat[-1], tmp_lon[-1], tmp_alt[-1],\n",
        "                              lat_head_noise[0], lon_head_noise[0], alt_head[0])\n",
        "\n",
        "    # Extend altitude sequence\n",
        "    tmp_alt = np.append(tmp_alt, alt_head)\n",
        "    \n",
        "    # Extend distance sequence\n",
        "    tmp_distance = np.append(tmp_distance, distance_head)\n",
        "\n",
        "    # Total distance\n",
        "    tmp_distance_sum = np.sum(tmp_distance)\n",
        "\n",
        "    return str(list(tmp_alt)), str(list(tmp_distance)), str(list(tmp_heart)), str(list(tmp_speed)), complete_idx, tmp_distance_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkzJaQYP1CHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9658d01-4030-4cf9-ebb6-0c66c0a26896"
      },
      "source": [
        "# Create new sequential features for training set\n",
        "\n",
        "%%time\n",
        "\n",
        "adjust_train_df['altitude_adjusted'], \\\n",
        "    adjust_train_df['distance_adjusted'], \\\n",
        "    adjust_train_df['heart_rate_adjusted'], \\\n",
        "    adjust_train_df['speed_adjusted'], \\\n",
        "    adjust_train_df['complete_idx'], \\\n",
        "    adjust_train_df['distance_adjusted_sum'] = zip(\n",
        "        *adjust_train_df.apply(lambda x: update_sequence(x, 100), axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 32min 58s, sys: 4.21 s, total: 33min 2s\n",
            "Wall time: 33min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFTBFlIwvOvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e7c280-5f2e-4b6a-bbeb-57d9540be881"
      },
      "source": [
        "np.isnan(adjust_train_df['distance_adjusted_sum'].to_numpy()).any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEb7X2Fb1CdD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab89a5e-4e9b-4e6e-8d66-52344047c89f"
      },
      "source": [
        "# Create new sequential features for test set\n",
        "\n",
        "%%time\n",
        "\n",
        "adjust_test_df['altitude_adjusted'], \\\n",
        "    adjust_test_df['distance_adjusted'], \\\n",
        "    adjust_test_df['heart_rate_adjusted'], \\\n",
        "    adjust_test_df['speed_adjusted'], \\\n",
        "    adjust_test_df['complete_idx'], \\\n",
        "    adjust_test_df['distance_adjusted_sum'] = zip(\n",
        "        *adjust_test_df.apply(lambda x: update_sequence(x, 100), axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8min 14s, sys: 501 ms, total: 8min 14s\n",
            "Wall time: 8min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWVfp_arvvt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48fbdc0f-f253-4ba5-b5ad-b21cadbb380b"
      },
      "source": [
        "np.isnan(adjust_test_df['distance_adjusted_sum'].to_numpy()).any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvZRPuYw44OM"
      },
      "source": [
        "# 5. Concatenate datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6awTfVQSoCjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fffedd24-f748-433e-d199-c5eb4014717d"
      },
      "source": [
        "# Concatenate the subset that returned to starting point and the subset that didn't return to starting point for training data\n",
        "\n",
        "%%time\n",
        "\n",
        "non_adjust_train_df = train_df[train_df.isback != 1].copy()\n",
        "non_adjust_train_df['altitude_adjusted'] = non_adjust_train_df.altitude\n",
        "non_adjust_train_df['distance_adjusted'] = non_adjust_train_df.derived_distance\n",
        "\n",
        "# Randomly chop off 0-9 points at tail\n",
        "non_adjust_train_df['complete_idx'] = non_adjust_train_df.apply(lambda x: random.randrange(490, 499), axis=1)\n",
        "non_adjust_train_df['speed_adjusted'] = non_adjust_train_df.apply(lambda x: str(eval(x.derived_speed)[:x.complete_idx]), axis=1)\n",
        "non_adjust_train_df['heart_rate_adjusted'] = non_adjust_train_df.apply(lambda x: str(eval(x.heart_rate)[:x.complete_idx]), axis=1)\n",
        "non_adjust_train_df['distance_adjusted_sum'] = non_adjust_train_df.distance\n",
        "\n",
        "train_df = pd.concat([non_adjust_train_df, adjust_train_df], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.2 s, sys: 2.38 s, total: 50.6 s\n",
            "Wall time: 50.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu-qcs1OQHYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0d079e-343f-4457-f1e6-fdbeea577326"
      },
      "source": [
        "# Concatenate the subset that returned to starting point and the subset that didn't return to starting point for test data\n",
        "\n",
        "%%time\n",
        "\n",
        "non_adjust_test_df = test_df[test_df.isback != 1].copy()\n",
        "non_adjust_test_df['altitude_adjusted'] = non_adjust_test_df.altitude\n",
        "non_adjust_test_df['distance_adjusted'] = non_adjust_test_df.derived_distance\n",
        "\n",
        "# Randomly chop off 0-9 points at tail\n",
        "non_adjust_test_df['complete_idx'] = non_adjust_test_df.apply(lambda x: random.randrange(490, 499), axis=1)\n",
        "non_adjust_test_df['speed_adjusted'] = non_adjust_test_df.apply(lambda x: str(eval(x.derived_speed)[:x.complete_idx]), axis=1)\n",
        "non_adjust_test_df['heart_rate_adjusted'] = non_adjust_test_df.apply(lambda x: str(eval(x.heart_rate)[:x.complete_idx]), axis=1)\n",
        "non_adjust_test_df['distance_adjusted_sum'] = non_adjust_test_df.distance\n",
        "\n",
        "test_df = pd.concat([non_adjust_test_df, adjust_test_df], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.7 s, sys: 20 ms, total: 11.7 s\n",
            "Wall time: 11.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed_sNw8CvLok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e6d123-4070-45e5-e68b-02a9aa847258"
      },
      "source": [
        "print(len(train_df))\n",
        "print(len(test_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50253\n",
            "12578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgSnjs9zW1lt"
      },
      "source": [
        "# https://drive.google.com/file/d/1gJTFdyq_yfRK1-PD3Y_S-UkDJIrseBVu/view?usp=sharing\n",
        "train_df.to_csv('/content/drive/My Drive/endomondoHR/Data/Dataset/[1109]TrainData_adjusted.csv',index=0)\n",
        "# https://drive.google.com/file/d/1-4WQdpOogRog7Jg_sP5SrOb802UTqpGc/view?usp=sharing\n",
        "test_df.to_csv('/content/drive/My Drive/endomondoHR/Data/Dataset/[1109]TestData_adjusted.csv',index=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Zajap_hfl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b7bd20-2c4a-46d8-dfe5-2a77cb21caa2"
      },
      "source": [
        "np.isnan(train_df['distance_adjusted_sum'].to_numpy()).any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gV5aZuSvodO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc73187-2d06-4206-930f-918deac1e9a9"
      },
      "source": [
        "np.isnan(test_df['distance_adjusted_sum'].to_numpy()).any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}